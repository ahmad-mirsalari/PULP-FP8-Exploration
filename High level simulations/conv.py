#!/bin/python3

import os
import argparse
import torch
import matplotlib.pyplot as plt
import sys
from fp_quantization import fp8_quantizer



def add_padding_to_image(img, padding_width: int):
    # Array of zeros of shape (img + padding_width)
    img_with_padding = torch.zeros((
        img.shape[0] + padding_width * 2,  # Multiply with two because we need padding on all sides
        img.shape[1] + padding_width * 2
    ))

    # Change the inner elements
    # For example, if img.shape = (224, 224), and img_with_padding.shape = (226, 226)
    # keep the pixel wide padding on all sides, but change the other values to be the same as img
    img_with_padding[padding_width:-padding_width, padding_width:-padding_width] = img

    return img_with_padding


def get_padding_width_per_side(kernel_size: int) -> int:
    # Simple integer division
    return kernel_size // 2  # p = [K/2]


def calculate_target_size(Img_Width, Kernel_Width, Stride, P):
    '''you can use this formula [(W-K+2P)/S]+1.
    W is the input volume - in your case 16
    K is the Kernel size - in your case 5
    P is the padding - 0 for valid and 1 is for same
    S is the stride - which you have not provided.'''
    W = Img_Width
    K = Kernel_Width
    S = Stride
    pixels = ((W - K + 2 * P) // S) + 1  # I added padding to input data, so I removed the 2P in this formula
    return pixels


def mac(img, kernel, dt, mac_flag, vec_flag, cast_flag, cast_to, MANTISA_BITS):

    if vec_flag == "false":
        if dt == "FP8_CUSTOM":
            temp = torch.zeros(1, dtype=torch.float32)
        else:
            temp = torch.zeros(1, dtype=dt)
        for i in range(img.shape[0]):
            for j in range(img.shape[1]):
                a = img[i][j]
                b = kernel[i][j]
                if cast_flag == "true":
                    if cast_to == "FP16":
                        a = a.type(torch.float16)
                        b = b.type(torch.float16)
                    elif cast_to == "FP16ALT":
                        a = a.type(torch.bfloat16)
                        b = b.type(torch.bfloat16)
                if mac_flag == "true" or dt == "FP8_CUSTOM":
                    a = a.type(torch.float32)
                    b = b.type(torch.float32)
                    temp = temp.type(torch.float32)
                temp += a * b
                if dt == "FP8_CUSTOM":
                    temp = fp8_quantizer(temp, torch.tensor(MANTISA_BITS))
                if mac_flag == "true":
                    temp = temp.type(dt)
        return temp
    else:
        flag = True
        temp = torch.zeros(1, dtype=dt)
        temp1 = torch.zeros(1, dtype=dt)
        for i in range(img.shape[0]):
            for j in range(0, (img.shape[1] & 0xfffffffe), 2):
                a = img[i][j]
                a1 = img[i][j + 1]
                b = kernel[i][j]
                b1 = kernel[i][j + 1]
                if mac_flag == "true":
                    a = a.type(torch.float32)
                    b = b.type(torch.float32)
                    a1 = a1.type(torch.float32)
                    b1 = b1.type(torch.float32)
                    temp = temp.type(torch.float32)
                    temp1 = temp1.type(torch.float32)
                temp += a * b
                temp1 += a1 * b1
                if mac_flag == "true":
                    temp = temp.type(dt)
                    temp1 = temp1.type(dt)
        if img.shape[1] & 0x00000001:
            for i in range(img.shape[0]):
                a = img[i][img.shape[1] - 1]
                b = kernel[i][img.shape[1] - 1]
                if flag:  # temp
                    if mac_flag == "true":
                        a = a.type(torch.float32)
                        b = b.type(torch.float32)
                        temp = temp.type(torch.float32)
                    temp += a * b
                    if mac_flag == "true":
                        temp = temp.type(dt)
                    flag = False
                else:  # temp1
                    if mac_flag == "true":
                        a = a.type(torch.float32)
                        b = b.type(torch.float32)
                        temp1 = temp1.type(torch.float32)
                    temp1 += a * b
                    if mac_flag == "true":
                        temp1 = temp1.type(dt)
                    flag = True
        return temp + temp1


def convolve(img, kernel, out_width, dt, Stride, mac_flag, vec_flag, cast_flag, cast_to, MANTISA_BITS):
    # Create an empty array of shape (out_width, out_width)
    if dt == "FP8_CUSTOM":
        out_img = torch.zeros((out_width, out_width), dtype=torch.float32)
    else:
        out_img = torch.zeros((out_width, out_width), dtype=dt)
    tgt_size = out_img.shape[0]
    # To simplify things
    k = kernel.shape[0]
    if vec_flag == "false":
        # Iterate over the rows
        for i in range(tgt_size):
            # Iterate over the columns
            for j in range(tgt_size):
                # img[i, j] = individual pixel value
                # Get the current matrix
                mat = img[i * Stride:i * Stride + k, j * Stride:j * Stride + k]
                # Apply the convolution - element-wise multiplication and summation of the result
                # Store the result to i-th row and j-th column of our convolved_img array
                out_img[i, j] = mac(mat, kernel, dt, mac_flag, vec_flag, cast_flag, cast_to, MANTISA_BITS)
    else:  # based on the vectorized c code
        # Iterate over the columns
        for j in range(tgt_size):
            # Iterate over the rows
            for i in range(tgt_size):
                # img[i, j] = individual pixel value
                # Get the current matrix
                mat = img[i * Stride:i * Stride + k, j * Stride:j * Stride + k]
                # Apply the convolution - element-wise multiplication and summation of the result
                # Store the result to i-th row and j-th column of our convolved_img array
                out_img[i, j] = mac(mat, kernel, dt, mac_flag, vec_flag, cast_flag, cast_to="false", MANTISA_BITS= MANTISA_BITS)
    return out_img


def relative_absolute_error(true, pred):
    true_mean = torch.mean(true)
    squared_error_num = torch.sum(torch.abs(true - pred))
    squared_error_den = torch.sum(torch.abs(true - true_mean))
    rae_loss = squared_error_num / squared_error_den
    return rae_loss


def mean_squared_error(true, pred):
    squared_error = torch.square(true - pred)
    sum_squared_error = torch.sum(squared_error)
    size = true.size(dim=0) * true.size(dim=1)
    mse_loss = sum_squared_error / size
    return mse_loss


def matrix_init(IN, dt):
    # iterate through rows of IN
    temp = torch.zeros((IN.shape[0], IN.shape[1]), dtype=dt)
    # iterate through rows of IN
    for i in range(IN.shape[0]):
        # iterate through columns of IN
        for j in range(IN.shape[1]):
            temp[i][j] = IN[i][j] 
    return temp
def matrix_init_custom(IN, MANTISA_BITS):
    temp = torch.zeros((IN.shape[0], IN.shape[1]), dtype=torch.float32)
    # iterate through rows of IN
    for i in range(IN.shape[0]):
        # iterate through columns of IN
        for j in range(IN.shape[1]):
            temp[i][j] = fp8_quantizer(IN[i][j], torch.tensor(MANTISA_BITS))
    return temp

def write_matrix(matrix_to_write, name, len, file_pointer, float_type):
    matrix_string = ''
    sz0 = matrix_to_write.size()[0]
    sz1 = matrix_to_write.size()[1]
    if 'Filter_Kern' in name:
        file_pointer.write("DATA_LOCATION FIL_TYPE %s[%s] = {" % (name, len))
    elif 'ref' in name:
        file_pointer.write("PI_L2 OUT_TYPE %s[%s] = {" % (name, len))
    else:
        file_pointer.write("DATA_LOCATION INP_TYPE %s[%s] = {" % (name, len))

    if float_type == torch.float32:
        name = ")"
    elif float_type == torch.float16:
        name = ", dtype=torch.float16)"
    elif float_type == torch.bfloat16:
        name = ", dtype=torch.bfloat16)"
    for i in range(sz0):
        for j in range(sz1):
            matrix_string += str(matrix_to_write[i][j].item()).replace('tensor(', '').replace(name, '')
            matrix_string += ', '
    file_pointer.write("%s" % matrix_string)
    file_pointer.write("};\n")


def select_dtypes(user_dtypes, num_param):
    types_dict = {
        "FP32": torch.float32,
        "FP16": torch.float16,
        "FP16ALT": torch.bfloat16,
        "FP8_CUSTOM": "FP8_CUSTOM"
    }
    dtypes = []
    if len(user_dtypes) == 1:
        for i in range(num_param):
            dtypes.append(types_dict[user_dtypes[0]])
    elif len(user_dtypes) == num_param:
        for i in range(num_param):
            dtypes.append(types_dict[user_dtypes[i]])
    else:
        for i in range(len(user_dtypes)):
            dtypes.append(types_dict[user_dtypes[i]])
        if 'FP32' in user_dtypes:
            for i in range(len(user_dtypes), num_param):
                dtypes.append(types_dict["FP32"])
        elif 'FP16' in user_dtypes:
            for i in range(len(user_dtypes), num_param):
                dtypes.append(types_dict["FP16"])
                dtypes.append(types_dict["BFP8"])
        elif 'FP8_CUSTOM' in user_dtypes:
            for i in range(len(user_dtypes), num_param):
                dtypes.append(types_dict["FP8_CUSTOM"])
        else:
            for i in range(len(user_dtypes), num_param):
                dtypes.append(types_dict["FP16ALT"])
    return dtypes

def check_cast(datatypes):
    result = len(set(datatypes)) == 1  
    if result : #All Elements in List are Equal
        return "false"
    else: #All Elements in List are Not Equal
        if torch.float32 in datatypes:
            return "false"
        else:
            return "true"

def get_inital_config():
    # get arguments  and data format
    parser = argparse.ArgumentParser()
    parser.add_argument('--IMG_WIDTH')
    parser.add_argument('--FILT_WIN')
    parser.add_argument('--STRIDE', default=1)
    parser.add_argument('--PADDING', default='valid')
    parser.add_argument('--std', default=1)
    parser.add_argument('--vec_flag', default="false")
    parser.add_argument('--MAC_flag', default="true")
    parser.add_argument('--float_type', default='FP32')
    args = parser.parse_args()

    IMG_WIDTH = int(args.IMG_WIDTH)
    FILT_WIN = int(args.FILT_WIN)
    STRIDE = int(args.STRIDE)
    PADDING = str(args.PADDING)
    std = float(args.std)
    mac_flag = str(args.MAC_flag)
    vec_flag = str(args.vec_flag)
    bits = args.float_type.split(",")
    if PADDING == 'same' and STRIDE != 1:
        sys.exit("ValueError: padding='same' is not supported for strided convolutions")
    return IMG_WIDTH, FILT_WIN, STRIDE, PADDING, std, bits, mac_flag, vec_flag


def save_data_into_hfile(OUT_WIDTH, IMG_WIDTH, FILT_WIN, STRIDE, res, filter_conv, input_conv):
    # Generate header file
    f = open('data.h', 'w')

    f.write('\
#ifndef _INPUT_IMAGE_ \n\
#define _INPUT_IMAGE_\n\
#pragma GCC diagnostic ignored "-Woverflow"\n\n')
    f.write('\
#define OUT_DIM %s\n\
#define OUT_ROW %s\n\
#define OUT_COL %s\n\
#define INP_COL %s\n\
#define STRIDE %s\n\
#define FILT_WIN %s\n\n' % (OUT_WIDTH * OUT_WIDTH, OUT_WIDTH, OUT_WIDTH, IMG_WIDTH, STRIDE, FILT_WIN))
    write_matrix(input_conv, 'In_Img', IMG_WIDTH * IMG_WIDTH, f, input_conv.dtype)
    write_matrix(filter_conv, 'Filter_Kern', FILT_WIN * FILT_WIN, f, filter_conv.dtype)
    write_matrix(res, 'ref', OUT_WIDTH * OUT_WIDTH, f, res.dtype)
    f.write('\
#endif \n')
    f.close()

    f = open('config.h', 'w')

    f.write('\
#define FILT_WIN %s \n\n' % FILT_WIN)
    f.close()

def error_metric(ref, res, output_file):

    # calculate manually because metrics doesn't supprt bfloat16
    d = ref - res
    mse_f = torch.mean(d**2)
    mae_f = torch.mean(abs(d))
    rmse_f = torch.sqrt(mse_f)
    r2_f = 1-(torch.sum(d**2)/torch.sum((ref-torch.mean(ref))**2))

    results = []

    # Append the results to a list
    results.append("Results of metrics:")
    results.append(f"MAE: {mae_f.item()}")
    results.append(f"MSE: {mse_f.item()}")
    results.append(f"RMSE: {rmse_f.item()}")
    results.append(f"R-Squared: {r2_f.item()}")
    
    rae = relative_absolute_error(ref, res)
    results.append(f"RAE is {rae.item()}")

    # If an output file is provided, write the results to it
    if output_file:
        with open(output_file, "w") as file:
            for result in results:
                file.write(result + "\n")
    
    # Otherwise, print the results to the console
    else:
        for result in results:
            print(result)
    return mse_f.item()


def main():
    IMG_WIDTH, FILT_WIN, STRIDE, PADDING, std, bits, mac_flag, vec_flag = get_inital_config()


    mean = 0
    # Create reference matrices

    input_ref = torch.normal(mean, std, (IMG_WIDTH, IMG_WIDTH))
    filter_ref = torch.normal(mean, std, (FILT_WIN, FILT_WIN))
    
    # Convert tensor to list for the histogram
    data = input_ref.flatten().tolist()

    OUT_WIDTH = IMG_WIDTH
    if PADDING == 'same':
        pad = get_padding_width_per_side(kernel_size=FILT_WIN)
        input_ref = add_padding_to_image(img=input_ref, padding_width=pad)
        OUT_WIDTH = IMG_WIDTH
        IMG_WIDTH = input_ref.shape[0]

    elif PADDING == 'valid':
        P = 0
        OUT_WIDTH = calculate_target_size(Img_Width=IMG_WIDTH,
Kernel_Width=FILT_WIN, Stride=STRIDE, P=P )
    # calculate reference output
    ref = convolve(img=input_ref, kernel=filter_ref, dt=torch.float32,
                   out_width=OUT_WIDTH, mac_flag="false", Stride=STRIDE, vec_flag="false", cast_flag="false", cast_to="false", MANTISA_BITS = 0)

    # set the data types based on the parser input
    datatypes = select_dtypes(bits, 3)
    cast_flag = check_cast(datatypes[0:2])
    cast_to = "FP16"

    output_folder = os.path.join(os.getcwd(), "conv", str(IMG_WIDTH), str(std))
    os.makedirs(output_folder, exist_ok=True)
    error_metrics = []
    mantissa_bits = []
    if datatypes[0] == "FP8_CUSTOM":
        for MANTISA_BITS in range(1,7):
            
            input_conv = matrix_init_custom(input_ref, MANTISA_BITS)
            filter_conv = matrix_init_custom(filter_ref, MANTISA_BITS)
            res = convolve(img=input_conv, kernel=filter_conv, dt=datatypes[2],
                        out_width=OUT_WIDTH, Stride=STRIDE, mac_flag=mac_flag, vec_flag=vec_flag, cast_flag=cast_flag, cast_to = cast_to, MANTISA_BITS = MANTISA_BITS)
            
            output_file =  os.path.join(output_folder,f"error_metric_{MANTISA_BITS}_{IMG_WIDTH}_{FILT_WIN}_{std}.txt")
            
            error = error_metric(ref, res, output_file)
            mantissa_bits.append(MANTISA_BITS)
            error_metrics.append(error)
        plt.tight_layout()

    else:

        input_conv = matrix_init(input_ref, dt=datatypes[0])
        filter_conv = matrix_init(filter_ref, dt=datatypes[1])
        res = convolve(img=input_conv, kernel=filter_conv, dt=datatypes[2],
                    out_width=OUT_WIDTH, Stride=STRIDE, mac_flag=mac_flag, vec_flag=vec_flag, cast_flag=cast_flag, cast_to = cast_to, MANTISA_BITS = 0)
        output_file =  os.path.join(output_folder,f"error_metric_{datatypes[0]}_{IMG_WIDTH}_{FILT_WIN}_{std}.txt")
        error_metric(ref, res, output_file)

    save_data_into_hfile(OUT_WIDTH, IMG_WIDTH, FILT_WIN, STRIDE, res, filter_conv, input_conv)
    return None


if __name__ == "__main__":
    main()
    pass